{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import cluster, metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import cdist \n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import string\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your ticker symbol:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " TSLA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-10</th>\n",
       "      <td>1396.0</td>\n",
       "      <td>1548.92</td>\n",
       "      <td>1376.01</td>\n",
       "      <td>1544.65</td>\n",
       "      <td>23281000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open     High      Low    Close    Volume  Dividends  \\\n",
       "Date                                                                 \n",
       "2020-07-10  1396.0  1548.92  1376.01  1544.65  23281000          0   \n",
       "\n",
       "            Stock Splits  \n",
       "Date                      \n",
       "2020-07-10             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Enter your ticker symbol:\")\n",
    "ticker = input()\n",
    "stock = yf.Ticker(ticker).history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Run our imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import re\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def articles(ticker):\n",
    "    \n",
    "    print('Gathering Articles')\n",
    "    \n",
    "    def get_article_links(ticker):\n",
    "        # Set the URL for gathering articles about the ticker\n",
    "        url = f'https://seekingalpha.com/symbol/{ticker}/news'\n",
    "\n",
    "        # open the Selenium driver to the url\n",
    "        driver = webdriver.Chrome('./chromedriver')\n",
    "        driver.implicitly_wait(50)\n",
    "        driver.get(url)\n",
    "        # gather the links for the most recent articles\n",
    "        links = driver.find_elements_by_class_name(\"_1-r1S\")\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df['date'] = [i.find_element_by_class_name(\"VbEwc\").text for i in links]\n",
    "        df['name'] = [i.find_element_by_tag_name(\"h3\").text for i in links]\n",
    "        df['href'] = [i.find_elements_by_tag_name('a')[0].get_property('href') for i in links]\n",
    "\n",
    "        # close the Seleium driver\n",
    "        driver.close()\n",
    "\n",
    "        # Clean it up to take out special characters from the article name\n",
    "        df['name'] = [re.sub('[^A-Za-z0-9 $]+', '', i) for i in df['name']]\n",
    "\n",
    "        # save info to dataframe\n",
    "        df.to_csv(f'./data/{ticker}_link_history.csv')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_articles(ticker):\n",
    "\n",
    "        df = get_article_links(ticker)\n",
    "\n",
    "        # Open the Selenium Driver\n",
    "        driver = webdriver.Chrome('./chromedriver')\n",
    "        #start a list of the articles\n",
    "        art_list = []\n",
    "        # grap the comments while I'm here\n",
    "        comments = []\n",
    "        # for loop to go through each of the links and grab the articles\n",
    "        for l in df['href']:\n",
    "            driver.get(l)\n",
    "            driver.implicitly_wait(50)\n",
    "            try:\n",
    "                article = driver.find_element_by_id(\"a-cont\")\n",
    "            except:\n",
    "                article = 'error'\n",
    "            # The Article has comments, which for now I am going to take out. This code will separate the article into two sections with \"Like this article\" as the separator\n",
    "            sep = 'Recommended for you:'\n",
    "            try:\n",
    "                art_list.append(article.text.split(sep,1)[0])\n",
    "            except:\n",
    "                art_list.append('error')\n",
    "            try:\n",
    "                comments.append(article.text.split(sep,1)[1])\n",
    "            except:\n",
    "                comments.append('error')\n",
    "        df['article'] = art_list\n",
    "\n",
    "        # close the Seleium driver\n",
    "        driver.close()\n",
    "\n",
    "        return df\n",
    "\n",
    "    df = get_articles(ticker)\n",
    "\n",
    "\n",
    "    # This function will run through the list again and re-try error pages\n",
    "    def finish_qurom(df):\n",
    "        driver = webdriver.Chrome('./chromedriver')\n",
    "        #start a list of the articles\n",
    "        art_list = []\n",
    "        # grap the comments while I'm here\n",
    "        comments = []\n",
    "        # for loop to go through each of the links and grab the articles\n",
    "        for r,c in df.iterrows():\n",
    "            if c[3] == 'error':\n",
    "                sep = 'Recommended for you:'\n",
    "                driver.get(c[2])\n",
    "                driver.implicitly_wait(50)\n",
    "                try:\n",
    "                    if driver.find_element_by_class_name('premium-banner'):\n",
    "                        df['article'][r] = 'premium-banner'\n",
    "                except:\n",
    "                    try:\n",
    "                        df['article'][r] = driver.find_element_by_id(\"a-cont\").text.split(sep,1)[0]\n",
    "                    except:\n",
    "                        article = 'error'\n",
    "                    try:\n",
    "                        df['comments'][r] = driver.find_element_by_id(\"a-cont\").text.split(sep,1)[1]\n",
    "                    except:\n",
    "                        comments.append('error')\n",
    "        driver.close()\n",
    "\n",
    "        return df\n",
    "\n",
    "    # run this new function to catch and sort errors\n",
    "    df1 = finish_qurom(df)\n",
    "\n",
    "    df = df1[df1.article != 'premium-banner']\n",
    "\n",
    "\n",
    "    print(\"Articles gathered...vectorizing\")\n",
    "    # import google's word2vec located: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "    w2v_model = KeyedVectors.load_word2vec_format('../../Downloads/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "    # function for converting articles and article names into KeyedVectors\n",
    "\n",
    "    def clean2vect(articles):\n",
    "        new_list = []\n",
    "        for a in articles:\n",
    "            new_list.append(a.replace(',','').translate(string.punctuation))\n",
    "\n",
    "        clean_articles = [word.split() for word in new_list]\n",
    "\n",
    "        vects = []\n",
    "\n",
    "        for a in clean_articles:\n",
    "            vector = []\n",
    "            for word in a:\n",
    "                try:\n",
    "                    vector.append(w2v_model[word])\n",
    "                except:\n",
    "                    continue\n",
    "            try:\n",
    "                vects.append(sum(vector)/len(vector))\n",
    "            except:\n",
    "                vects.append(1)\n",
    "        return vects\n",
    "\n",
    "    # run both df columns through the clean2vect function which will append them to the df\n",
    "    df['article_vect'] = clean2vect(df['article'])\n",
    "    df['name_vect'] = clean2vect(df['name'])    \n",
    "    \n",
    "    print(\"Vectorized...seting datetime index\")\n",
    "\n",
    "    # clean up the dates from the articles to match the datetime format of the stock def\n",
    "    def art_date(df):\n",
    "        dates = []\n",
    "        for i in df.date:\n",
    "            if \"Today\" in i:\n",
    "                dates.append('2020-' + str(i.replace(i, date.today().strftime(\"%m-%d\"))))\n",
    "            elif 'Sat, Feb. 29' in i:\n",
    "                dates.append('2020-03-01')\n",
    "            elif \"Yesterday\" in i:\n",
    "                dates.append('2020-' + str(i.replace(i, (date.today() - timedelta(days = 1)).strftime(\"%m-%d\"))))\n",
    "            else:\n",
    "                try:\n",
    "                    dates.append('2020-' + str(datetime.strptime(i,'%a, %b. %d').strftime('%m-%d')))\n",
    "                except:\n",
    "                    try:\n",
    "                        dates.append('2020-' + str(datetime.strptime(i,'%a, %b %d').strftime('%m-%d')))\n",
    "                    except:\n",
    "                        dates.append(str(datetime.strptime(i,'%a, %b. %d, %Y').strftime('%Y-%m-%d')))\n",
    "        # set dataframe to new dates columns as index\n",
    "        df.date = dates\n",
    "        df.date = pd.to_datetime(df['date'])\n",
    "        df.set_index('date', inplace=True)\n",
    "        df.sort_index(inplace=True)\n",
    "        return df\n",
    "\n",
    "    df = art_date(df)\n",
    "\n",
    "    print('Datetime Ready...Clustering...')\n",
    "\n",
    "    # Import pickle of trained KMeans Article Cluster Model\n",
    "    art_kluster_model = open('./pickle_jar/art_clusterer_pkl', 'rb')\n",
    "    art_kclusterer = pickle.load(art_kluster_model)\n",
    "    art_kluster_model.close()\n",
    "\n",
    "    # Import pickle of trained KMeans Name Cluster Model\n",
    "    name_kluster_model = open('./pickle_jar/name_clusterer_pkl', 'rb')\n",
    "    name_kclusterer = pickle.load(name_kluster_model)\n",
    "    name_kluster_model.close()\n",
    "\n",
    "\n",
    "    # assign clusters to new articles based on trained model\n",
    "    df['art_clusters'] = [art_kclusterer.classify_vectorspace(vector) for vector in df['article_vect']]\n",
    "    df['name_clusters'] = [name_kclusterer.classify_vectorspace(vector) for vector in df['article_vect']]\n",
    "\n",
    "    # pickle articles dataframe with new info before merging to X Features\n",
    "    with open('./pickle_jar/articles_predict', 'wb') as fp:\n",
    "        pickle.dump(df, fp)    \n",
    "\n",
    "    df.drop(['name','article','href', 'article_vect','name_vect'], axis=1, inplace=True)\n",
    "    \n",
    "    print('Getting Ticker Info')\n",
    "    \n",
    "    def get_stock(ticker):\n",
    "        stock = yf.Ticker(ticker).history()\n",
    "        stock.columns = [i.lower() for i in stock.columns]\n",
    "        stock = stock.pct_change()\n",
    "        stock[['dividends','stock splits']] = stock[['dividends','stock splits']].fillna(0)\n",
    "        stock.dropna(inplace=True)\n",
    "\n",
    "        return stock\n",
    "    \n",
    "    stock = get_stock(ticker)\n",
    "    \n",
    "    X = pd.merge(stock, df.groupby('date').mean(), left_index=True, right_index=True, how='right')\n",
    "    X.ffill(inplace=True)\n",
    "    X.fillna(2, inplace=True)\n",
    "    \n",
    "    # get the model scaler\n",
    "    dbfile = open('./pickle_jar/model_scaler', 'rb')      \n",
    "    sc = pickle.load(dbfile) \n",
    "    dbfile.close() \n",
    "    \n",
    "    #scale the new X and create dummy target column\n",
    "    X_new_sc = sc.transform(X)\n",
    "    y_dummy = np.zeros((X_new_sc.shape[0], ))\n",
    "\n",
    "    print('Modeling Predictions')\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = load_model('./pickle_jar/model_1.h5')\n",
    "    \n",
    "    # create new test sequencer for new data\n",
    "    new_test_seq = TimeseriesGenerator(X_new_sc\n",
    "                                   , y_dummy\n",
    "                                   , length=3\n",
    "                                   , batch_size=64)\n",
    "    #predict classes of new data on the trained model\n",
    "    answer = model.predict(new_test_seq)\n",
    "    # add predictions to dataframe\n",
    "    X['first'] = [0,0,0] + [1 if i[0][0] >= .5 else 0 for i in answer]\n",
    "    X['second'] = [0,0,0] + [1 if i[1][0] >= .5 else 0 for i in answer]\n",
    "    X['third'] = [0,0,0] + [1 if i[1][0] >= .5 else 0 for i in answer]\n",
    "    X['prediction'] = [(c[9] + c[10] + c[11]) for r,c in X.iterrows()]\n",
    "\n",
    "    with open('./pickle_jar/answer', 'wb') as fp:\n",
    "        pickle.dump(X, fp)    \n",
    "    \n",
    "    if X['prediction'][-1] == 3.0:\n",
    "        return f'Today we are predicting you should BUY {ticker} stock'\n",
    "    elif X['prediction'][-1] == 0.0:\n",
    "        return f'Today we are predicting you should SELL {ticker} stock'\n",
    "    else:\n",
    "        return f'Today we are predicting a HOLD for {ticker} stock'\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering Articles\n",
      "Articles gathered...vectorizing\n",
      "Vectorized...seting datetime index\n",
      "Datetime Ready...Clustering...\n",
      "Getting Ticker Info\n",
      "Modeling Predictions\n",
      "WARNING:tensorflow:From <ipython-input-6-a12faf15649d>:243: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Today we are predicting you should BUY TSLA stock'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('./pickle_jar/answer', 'rb')      \n",
    "answer = pickle.load(dbfile) \n",
    "dbfile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('./pickle_jar/articles_predict', 'rb')      \n",
    "df = pickle.load(dbfile) \n",
    "dbfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(['name','article','href', 'article_vect','name_vect'], axis=1, inplace=True)\n",
    "\n",
    "def get_stock(ticker):\n",
    "    stock = yf.Ticker(ticker).history()\n",
    "    stock.columns = [i.lower() for i in stock.columns]\n",
    "    stock = stock.pct_change()\n",
    "    stock[['dividends','stock splits']] = stock[['dividends','stock splits']].fillna(0)\n",
    "    stock.dropna(inplace=True)\n",
    "\n",
    "    return stock\n",
    "\n",
    "stock = get_stock(ticker)\n",
    "\n",
    "X = pd.merge(stock, df.groupby('date').mean(), left_index=True, right_index=True, how='right')\n",
    "X.ffill(inplace=True)\n",
    "X.fillna(2, inplace=True)\n",
    "\n",
    "# get the model scaler\n",
    "dbfile = open('./pickle_jar/model_scaler', 'rb')      \n",
    "sc = pickle.load(dbfile) \n",
    "dbfile.close() \n",
    "\n",
    "#scale the new X and create dummy target column\n",
    "X_new_sc = sc.transform(X)\n",
    "y_dummy = np.zeros((X_new_sc.shape[0], ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the trained model\n",
    "model = load_model('./pickle_jar/model_1.h5')\n",
    "\n",
    "# create new test sequencer for new data\n",
    "new_test_seq = TimeseriesGenerator(X_new_sc\n",
    "                               , y_dummy\n",
    "                               , length=3\n",
    "                               , batch_size=64)\n",
    "#predict classes of new data on the trained model\n",
    "answer = model.predict(new_test_seq)\n",
    "# add predictions to dataframe\n",
    "X['first'] = [0,0,0] + [1 if i[0][0] >= .7 else 0 for i in answer]\n",
    "X['second'] = [0,0,0] + [1 if i[1][0] >= .7 else 0 for i in answer]\n",
    "X['third'] = [0,0,0] + [1 if i[1][0] >= .7 else 0 for i in answer]\n",
    "X['prediction'] = [(c[9] + c[10] + c[11]) for r,c in X.iterrows()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock splits</th>\n",
       "      <th>art_clusters</th>\n",
       "      <th>name_clusters</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>third</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>0.076006</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.076485</td>\n",
       "      <td>0.036877</td>\n",
       "      <td>-0.212288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>0.127867</td>\n",
       "      <td>0.081624</td>\n",
       "      <td>0.097270</td>\n",
       "      <td>0.079517</td>\n",
       "      <td>0.294382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>0.045199</td>\n",
       "      <td>0.121979</td>\n",
       "      <td>0.067848</td>\n",
       "      <td>0.134794</td>\n",
       "      <td>0.192451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>0.100510</td>\n",
       "      <td>0.037531</td>\n",
       "      <td>0.055820</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.044716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.008562</td>\n",
       "      <td>-0.018979</td>\n",
       "      <td>-0.017254</td>\n",
       "      <td>-0.240971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-09</th>\n",
       "      <td>-0.005701</td>\n",
       "      <td>-0.006139</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.020792</td>\n",
       "      <td>-0.281627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-10</th>\n",
       "      <td>-0.000709</td>\n",
       "      <td>0.099648</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.107848</td>\n",
       "      <td>0.986840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-11</th>\n",
       "      <td>-0.000709</td>\n",
       "      <td>0.099648</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.107848</td>\n",
       "      <td>0.986840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-12</th>\n",
       "      <td>-0.000709</td>\n",
       "      <td>0.099648</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.107848</td>\n",
       "      <td>0.986840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close    volume  dividends  \\\n",
       "date                                                                      \n",
       "2020-07-01  0.076006  0.043799  0.076485  0.036877 -0.212288        0.0   \n",
       "2020-07-02  0.127867  0.081624  0.097270  0.079517  0.294382        0.0   \n",
       "2020-07-06  0.045199  0.121979  0.067848  0.134794  0.192451        0.0   \n",
       "2020-07-07  0.100510  0.037531  0.055820  0.013328  0.044716        0.0   \n",
       "2020-07-08 -0.000007 -0.008562 -0.018979 -0.017254 -0.240971        0.0   \n",
       "2020-07-09 -0.005701 -0.006139  0.030457  0.020792 -0.281627        0.0   \n",
       "2020-07-10 -0.000709  0.099648  0.018301  0.107848  0.986840        0.0   \n",
       "2020-07-11 -0.000709  0.099648  0.018301  0.107848  0.986840        0.0   \n",
       "2020-07-12 -0.000709  0.099648  0.018301  0.107848  0.986840        0.0   \n",
       "\n",
       "            stock splits  art_clusters  name_clusters  first  second  third  \\\n",
       "date                                                                          \n",
       "2020-07-01           0.0      0.500000            1.0      0       0      0   \n",
       "2020-07-02           0.0      0.333333            1.0      0       0      0   \n",
       "2020-07-06           0.0      1.000000            1.0      0       0      0   \n",
       "2020-07-07           0.0      1.000000            1.0      0       1      1   \n",
       "2020-07-08           0.0      0.500000            1.0      0       1      1   \n",
       "2020-07-09           0.0      1.000000            1.0      0       1      1   \n",
       "2020-07-10           0.0      1.000000            1.0      0       0      0   \n",
       "2020-07-11           0.0      0.000000            1.0      0       0      0   \n",
       "2020-07-12           0.0      0.000000            1.0      0       0      0   \n",
       "\n",
       "            prediction  \n",
       "date                    \n",
       "2020-07-01         0.0  \n",
       "2020-07-02         0.0  \n",
       "2020-07-06         0.0  \n",
       "2020-07-07         2.0  \n",
       "2020-07-08         2.0  \n",
       "2020-07-09         2.0  \n",
       "2020-07-10         0.0  \n",
       "2020-07-11         0.0  \n",
       "2020-07-12         0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first'] = [0,0,0] + [i[0][0] for i in answer]\n",
    "df['second'] = [0,0,0] + [i[1][0] for i in answer]\n",
    "df['third'] = [0,0,0] + [i[2][0] for i in answer]\n",
    "df['prediction'] = [(c[9] + c[10] + c[11]) for r,c in df.iterrows()]\n",
    "df['answer'] = [1 if c[2] > .01 else 0 for r,c in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import article_gather\n",
    "articles()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
